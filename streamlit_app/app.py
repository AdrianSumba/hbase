import streamlit as st
import pandas as pd
import happybase
from sqlalchemy import create_engine

# =============================
# FUNCIONES CRISP-DM + HBASE
# =============================

def cargar_csvs_multiple(rutas: dict) -> dict:
    dict_dfs = {nombre: pd.read_csv(ruta) for nombre, ruta in rutas.items()}
    return dict_dfs


def entender_datos(df: pd.DataFrame):
    st.write("### Info")
    st.write(df.info())
    st.write("### Descripci√≥n")
    st.write(df.describe(include='all'))
    st.write("### Nulos")
    st.write(df.isnull().sum())


def limpiar_datos(df: pd.DataFrame) -> pd.DataFrame:
    df = df.drop_duplicates()
    df = df.dropna(how='all')
    df = df.fillna(df.median(numeric_only=True))
    return df


def cargar_multiples_tablas_hbase(dict_dfs: dict, host: str):
    # üëá CORRECCI√ìN: especificar puerto de Thrift (9091 en Docker)
    connection = happybase.Connection(host=host, port=9091)
    connection.open()

    familias = {"cf1": dict()}
    tablas_existentes = connection.tables()

    for nombre_tabla, df in dict_dfs.items():
        if nombre_tabla.encode() not in tablas_existentes:
            connection.create_table(nombre_tabla, familias)

        t = connection.table(nombre_tabla)

        for i, row in df.iterrows():
            data_dict = {}
            for col in df.columns:
                valor = row[col]
                if pd.notnull(valor):
                    data_dict[f"cf1:{col}"] = str(valor).encode()
            t.put(str(i).encode(), data_dict)

        st.success(f"Tabla '{nombre_tabla}' cargada en HBase.")

    connection.close()



# ==================================================================
# APLICACI√ìN STREAMLIT
# ==================================================================

st.title("Pipeline CRISP-DM con Upload a HBase")
st.markdown("---")

# 1. SUBIR CSVs
st.header("1. Cargar CSVs para procesar")
clientes = st.file_uploader("Clientes", type=["csv"])
metodos = st.file_uploader("M√©todos de Pago", type=["csv"])
categorias = st.file_uploader("Categor√≠as", type=["csv"])
productos = st.file_uploader("Productos", type=["csv"])
ventas = st.file_uploader("Ventas", type=["csv"])

if st.button("Procesar CSVs"):
    rutas = {}

    if clientes: rutas["clientes"] = clientes
    if metodos: rutas["metodos_pago"] = metodos
    if categorias: rutas["categorias"] = categorias
    if productos: rutas["productos"] = productos
    if ventas: rutas["ventas"] = ventas

    if len(rutas) == 0:
        st.error("Debe subir al menos un archivo CSV.")
    else:
        dict_dfs = {name: pd.read_csv(file) for name, file in rutas.items()}

        st.success("Archivos CSV cargados correctamente.")
        st.session_state["dict_raw"] = dict_dfs

# 2. ENTENDIMIENTO DE DATOS
if "dict_raw" in st.session_state:
    st.header("2. Entendimiento de Datos (CRISP-DM)")
    for nombre, df in st.session_state["dict_raw"].items():
        st.subheader(f"Dataset: {nombre}")
        st.write(df.head())
        entender_datos(df)

# 3. LIMPIEZA DE DATOS
if "dict_raw" in st.session_state:
    if st.button("Limpiar Datos"):
        dict_limpio = {n: limpiar_datos(df) for n, df in st.session_state["dict_raw"].items()}
        st.session_state["dict_clean"] = dict_limpio
        st.success("Datos limpiados correctamente.")

# ‚≠ê‚≠ê‚≠ê NUEVO BOT√ìN: VER DATOS LIMPIOS ‚≠ê‚≠ê‚≠ê
if "dict_clean" in st.session_state:
    if st.button("Ver datos limpios antes de subir"):
        st.subheader("üìå Datos limpios")
        for nombre, df in st.session_state["dict_clean"].items():
            st.write(f"### {nombre}")
            st.dataframe(df)

# 4. SUBIR A HBASE
if "dict_clean" in st.session_state:
    st.header("4. Subir Datos Limpiados a HBase")
    host = st.text_input("Host HBase", "localhost")

    if st.button("Subir a HBase"):
        cargar_multiples_tablas_hbase(st.session_state["dict_clean"], host)
        st.success("Proceso completo CRISP-DM ejecutado.")

# ================================
# 5. MODELADO COMPLETO CON TODAS LAS TABLAS
# ================================
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

if "dict_clean" in st.session_state:

    st.header("5. Modelado Predictivo con Todas las Tablas")

    # Cargar data limpia
    df_v = st.session_state["dict_clean"].get("ventas")
    df_p = st.session_state["dict_clean"].get("productos")
    df_c = st.session_state["dict_clean"].get("categorias")
    df_m = st.session_state["dict_clean"].get("metodos_pago")
    df_cl = st.session_state["dict_clean"].get("clientes")

    # Validar tablas
    if df_v is not None and df_p is not None:

        # ---------------------------------------
        # 1Ô∏è‚É£ JOIN: ventas + productos
        # ---------------------------------------
        df = df_v.merge(df_p, on="ID_Producto", how="left")

        # ---------------------------------------
        # 2Ô∏è‚É£ JOIN: productos + categorias
        # ---------------------------------------
        if "Categor√≠a" in df.columns and "Categor√≠a" in df_c.columns:
            df = df.merge(df_c, on="Categor√≠a", how="left")

        # ---------------------------------------
        # 3Ô∏è‚É£ JOIN: ventas + clientes
        # ---------------------------------------
        if "ID_Cliente" in df.columns and "ID_Cliente" in df_cl.columns:
            df = df.merge(df_cl, on="ID_Cliente", how="left")

        # ---------------------------------------
        # 4Ô∏è‚É£ JOIN: ventas + metodos_pago
        # Coincide por nombre del m√©todo
        # ---------------------------------------
        if "M√©todo_Pago" in df.columns and "M√©todo" in df_m.columns:

        # üëá CORRECCI√ìN: asegurar que ambas columnas sean strings
            df["M√©todo_Pago"] = df["M√©todo_Pago"].astype(str)
            df_m["M√©todo"] = df_m["M√©todo"].astype(str)

            df = df.merge(df_m, left_on="M√©todo_Pago", right_on="M√©todo", how="left")


        st.subheader("Dataset unificado final")
        st.dataframe(df.head())

        # ===========================
        # 5Ô∏è‚É£ Selecci√≥n de variables
        # ===========================
        y = df["Cantidad"]  # Variable objetivo

        # Variables predictoras reales disponibles
        variables = [
            "Precio_Unitario",
            "Stock",
            "Categor√≠a",
            "M√©todo_Pago",
            "Estado",
            "Regi√≥n",
            "Nombre_producto"
        ]

        # Filtrar solo columnas que existen
        variables = [v for v in variables if v in df.columns]

        X = df[variables]

        # Columnas categ√≥ricas y num√©ricas
        cat_cols = X.select_dtypes(include="object").columns.tolist()
        num_cols = X.select_dtypes(include="number").columns.tolist()

        # ===========================
        # 6Ô∏è‚É£ Pipeline de modelado
        # ===========================
        preprocessor = ColumnTransformer(
            transformers=[
                ("cat", OneHotEncoder(handle_unknown="ignore"), cat_cols),
                ("num", "passthrough", num_cols),
            ]
        )

        modelo = Pipeline(steps=[
            ("prep", preprocessor),
            ("reg", LinearRegression())
        ])

        # ===========================
        # 7Ô∏è‚É£ Entrenamiento
        # ===========================
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        modelo.fit(X_train, y_train)

        y_pred = modelo.predict(X_test)

        st.subheader("Predicci√≥n vs Real")
        st.write(pd.DataFrame({"Real": y_test.values, "Predicho": y_pred}).head())

        # ===========================
        # 8Ô∏è‚É£ Evaluaci√≥n del modelo
        # ===========================
        st.header("6. Evaluaci√≥n del Modelo")

        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

        st.metric("MSE", round(mse, 4))
        st.metric("R¬≤ Score", round(r2, 4))


        # ===========================
        # 9Ô∏è‚É£ Gr√°ficas finales
        # ===========================
        st.header("7. Visualizaci√≥n")

        # --- Gr√°fico 1: Cantidad por Categor√≠a ---
        st.subheader("1Ô∏è‚É£ Cantidad Total por Categor√≠a")
        fig1, ax1 = plt.subplots()
        df.groupby("Categor√≠a")["Cantidad"].sum().plot(kind="bar", ax=ax1)
        ax1.set_xlabel("Categor√≠a")
        ax1.set_ylabel("Cantidad Total")
        st.pyplot(fig1)

        # --- Gr√°fico 2: Ventas por M√©todo de Pago ---
        st.subheader("2Ô∏è‚É£ Ventas por M√©todo de Pago")
        fig2, ax2 = plt.subplots()
        df.groupby("M√©todo_Pago")["Cantidad"].sum().plot(kind="bar", ax=ax2)
        ax2.set_xlabel("M√©todo de Pago")
        ax2.set_ylabel("Cantidad Vendida")
        st.pyplot(fig2)

        # --- Gr√°fico 3: Precio vs Cantidad Vendida ---
        st.subheader("3Ô∏è‚É£ Relaci√≥n Precio Unitario vs Cantidad Vendida")
        fig3, ax3 = plt.subplots()
        ax3.scatter(df["Precio_Unitario"], df["Cantidad"])
        ax3.set_xlabel("Precio Unitario")
        ax3.set_ylabel("Cantidad")
        st.pyplot(fig3)

    else:
        st.error("Debes subir al menos las tablas 'ventas' y 'productos'.")
